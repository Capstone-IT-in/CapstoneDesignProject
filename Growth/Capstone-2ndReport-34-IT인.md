<!-- Template for PROJECT REPORT of CapstoneDesign 2025-2H, initially written by khyoo -->
<!-- 본 파일은 2025년도 컴공 졸업프로젝트의 <1차보고서> 작성을 위한 기본 양식입니다. -->
<!-- 아래에 "*"..."*" 표시는 italic체로 출력하기 위해서 사용한 것입니다. -->
<!-- "내용"에 해당하는 부분을 지우고, 여러분 과제의 내용을 작성해 주세요. -->

# Team-Info
| (1) 과제명 | *Linceiver IO: Reducing Computational Cost in Federated Learning with Adaptive Low-Rank Perceiver IO*
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | *34-IT인* |
| (3) 팀 구성원 | 심영은 (2194058): 리더, *실험용 서버구축 및 운영, 연합학습 환경 설계 및 구현, 통계분석 및 시각화* <br> 김경희 (2276034): 팀원, *모델 경량화 및 효율성 최적화, seqeunce length에 적응적으로 대응하는 모델 설계 및 구현* <br> 이채원 (2171039) : 팀원, *팀 레포지토리 및 산출물 관리, 모델 최적화 및 성능 개선, 실험 확장을 위한 다중 데이터셋 통합 구축 및 데이터 전처리*			 |
| (4) 팀 지도교수 | *이형준 교수님* |
| (5) 과제 분류 | *연구 과제* |
| (6) 과제 키워드 | *Perceiver IO, Linformer, Federated Learning*  |
| (7) 과제 내용 요약 | 현대의 분산 데이터 환경에서는 클라이언트들이 서로 다른 데이터 유형을 보유하고 있으며, 이는 연합학습의 성능 저하로 이어진다. 본 과제는 멀티모달 연합학습에서 이질성 문제(Heterogeneity Gap)를 해결하면서도, 자원이 부족한 디바이스에서도 사용 가능한 경량 모델을 개발하고자 한다. 이 프로젝트에서는 범용성이 뛰어난 Perceiver IO 모델을 컴퓨팅 자원이 부족한 연합학습 클라이언트에 적용하기 위한 경량화 모델인 Linceiver IO를 제안한다. Linceiver IO의 경우 Perceiver IO의 attention 연산에 Linformer 구조를 적용하여 계산 복잡도를 줄일 수 있다. |


<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | 본 과제는 멀티모달 연합학습 환경에서 발생하는 데이터 이질성 문제(Heterogeneity Gap)와 복잡한 모델 구조로 인한 클라이언트 모델의 자원 초과 문제를 동시에 해결하는 것을 목표로 한다. <br><br> **1. Heterogeneity Gap**<br>연합학습은 각 클라이언트가 데이터를 로컬에 저장한 채로 공동 학습을 가능하게 하지만, 현실 세계의 클라이언트들은 서로 다른 형태의 데이터를 보유하고 있다.<br>이로 인해 다음과 같은 문제가 발생한다:<br>- 클라이언트마다 입력 모달리티가 달라 통합된 모델 학습이 어려움<br>- 글로벌 모델이 특정 모달리티에 편향되거나 성능이 불균형하게 됨<br><br>기존의 멀티모달 연합학습 방법들은 일반적으로 특정 모달리티 조합을 미리 정한 후, 이에 따라 발생하는 Heterogeneity Gap을 해소하는 방식으로 문제에 접근하였다. 그러나 이 방식은 사전에 정한 모달리티 조합에서만 효과적이며, 새로운 모달리티 추가나 구성 변화에 유연하게 대응하지 못한다.<br>이러한 한계를 해결하려면 다양한 입력 모달리티를 유연하게 처리할 수 있는 모델 구조가 필요하다. 특히, 통합된 모델이 별도의 모달리티 특화된 구조 없이 다양한 데이터를 처리할 수 있어야 하며, 구조적 변경 없이도 새로운 모달리티가 추가될 때 쉽게 확장 가능한 모델이 요구된다.<br><br>**2. Client 모델 자원 초과 문제**<br>연합학습 환경의 클라이언트는 보통 스마트폰, IoT 센서, 엣지 장비 등으로, 컴퓨터 성능 및 메모리 같은 리소스가 매우 제한적이다. 이러한 환경에서 범용성만을 강조한 고성능 모델을 사용하게 되면 자원 초과 문제가 발생할 수 있다.<br>자원 초과 문제로 인해 나타나는 현상 및 피해는 다음과 같다.<br>- 모델의 폭주: 메모리 오버플로우로 인한 프로그램 종료나 디바이스의 강제 재부팅 현상 발생, 디바이스의 과열 또는 비정상적인 배터리 소모 증가<br>- 모델 추론 및 학습 실패: 과도한 연산량으로 인해 실시간 처리가 지연되거나 실패, 연합학습 과정에서 클라이언트의 참여 중단이 발생하여 전체 학습 성능 저하 초래<br>- 클라이언트의 시스템 불안정성: 제한된 리소스가 계속 초과되면 디바이스의 전반적인 안정성에 악영향을 미치며, 사용자 경험을 현저히 저하시킴<br><br>따라서 제한된 자원을 가진 클라이언트 디바이스에서도 효율적으로 운영 가능한, 경량화된 모델 아키텍처 및 최적화 기법이 요구된다. 이를 위해 연산 효율을 높이면서 자원 사용량을 최소화할 수 있는 구조를 도입하는 것이 필요하다.|
| (2) 기존연구와의 비교 | 본 과제에서 제안하는 Linceiver IO 모델은 기존의 유사한 접근법들인 단일 모달리티 기반의 연합학습 및 Perceiver IO 모델과 비교하여 명확한 차별점을 가지고 있다.<br><br> <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/TABLE2.jpg?raw=true" alt="비교" width="900"/> <br><br> **1. 단일 모달리티 연합학습과의 비교**<br>단일 모달리티 기반의 연합학습은 특정 데이터 유형(텍스트, 이미지, 센서 데이터 등)에 특화되어 있어, 해당 모달리티의 특성을 최대한 살려 높은 정확도와 최적의 성능을 제공할 수 있다. 예를 들어, Google의 Gboard 키보드 추천 시스템(텍스트 모달리티)이나 Apple의 Face ID 얼굴 인식 시스템(이미지 모달리티)은 특정 데이터에 특화된 최적화를 통해 매우 정밀하고 개인화된 결과를 제공하며, 개인정보 보호 측면에서도 강점을 가진다. 그러나 이러한 접근법은 모달리티 간의 데이터 통합이나 다양한 형태의 데이터를 활용한 일반화된 학습에는 적합하지 않다는 한계를 가진다. <br> 이에 비해 Linceiver IO는 다양한 형태의 데이터를 동시에 처리하는 멀티모달 통합 모델로, 서로 다른 모달리티를 가진 데이터를 효과적으로 통합하여 보다 풍부하고 일반화된 정보를 얻을 수 있다.<br><br>**2. 기존 멀티모달 모델 기반 연합학습과의 비교**<br>기존의 멀티모달 모델 기반 연합학습 접근법 중 대표적인 FedCLIP 모델은 이미지와 텍스트 데이터 쌍을 활용하여 성능을 향상시킨 사례이지만, 이미지와 텍스트라는 특정 모달리티 조합에 한정된 구조로 설계되어 있어, 새로운 모달리티가 추가될 경우 구조적 수정 및 재학습이 필수적이라는 단점이 존재한다. 또한 기존의 멀티모달 모델들은 일반적으로 모달리티마다 별도의 인코더나 특징 추출기를 운영하는 방식으로 인해 모델 관리와 유지보수가 복잡하고, 모달리티 구성이 변경될 때 재설계가 필요하다는 문제를 안고 있다. <br> Linceiver IO는 이러한 기존 방식의 한계를 극복하기 위해 별도의 복잡한 모델을 모달리티별로 관리하지 않고, 하나의 통합된 Perceiver IO 기반 모델을 사용하여 텍스트, 이미지, 센서 등 다양한 입력을 동시에 처리한다. 이로 인해 새로운 모달리티가 추가되거나 기존 모달리티의 구성이 변경되더라도 모델 구조의 수정이 거의 필요하지 않다는 장점이 있다.<br><br>**3. Perceiver IO와의 비교**<br>기존의 Perceiver IO 모델은 다양한 입력 모달리티와 데이터의 길이에 상관없이 유연하게 학습할 수 있는 매우 뛰어난 범용성을 가진 모델이다. 특히 모달리티의 다양성이나 입력 데이터의 길이 차이가 큰 환경에서도 별도의 사전 처리 없이 통합적인 학습이 가능하다는 강력한 장점이 있다. 이러한 특성 덕분에 멀티모달 데이터를 통합적으로 처리할 수 있는 차세대 범용 모델로 주목받고 있다. <br> 하지만 Perceiver IO는 높은 범용성과 뛰어난 성능의 대가로 연산 복잡도가 매우 높다는 치명적인 단점을 가진다. Attention 연산의 복잡도는 입력 시퀀스 길이의 제곱에 비례하여 증가하기 때문에, 긴 입력 데이터가 주어지면 계산과 메모리 사용량이 급격히 증가하여 클라이언트 단에서 실행하기 어렵다. 스마트폰, IoT 디바이스와 같은 자원이 제한된 환경에서는 모델이 자원을 초과하여 시스템이 불안정해지는 폭주(explode) 현상이 발생할 수 있다. <br> Linceiver IO는 이러한 한계를 극복하기 위해 Perceiver IO의 Attention 연산에 Linformer의 저차원 근사를 도입하여 연산량을 크게 절감하였다. 이로 인해 경량 디바이스에서도 높은 성능과 안정적인 실행이 가능한 효율적인 멀티모달 연합학습 모델로 발전시켰다.|
| (3) 제안 내용 | 1. **Multi-modal 연합학습의 유연성 향상** <br> 기존 Multi-modal 연합학습은 학습 가능한 모달리티가 정해져 있다. 즉, 이미지-텍스트를 학습하는 모델이라면 그 외의 영상이나 음성과 같은 다른 input에 대한 일반화 성능이 떨어지는 한계가 존재한다. 하지만, 본 연구는 다양한 모달리티의 데이터를 통합적으로 처리 가능한 멀티모달 모델인 Perceiver IO를 활용하여 client가 사용하는 모달리티에 제약을 받지 않는 보다 유연한 연합학습 환경을 제안한다.  <br><br> 2. **Perceiver IO의 경량화 및 연합학습 통합**  <br> Perceiver IO는 앞서 말한 것처럼 다양한 모달리티의 데이터를 모두 학습할 수 있는 범용성 있는 multi-modal 학습을 가능하게 하는 강력한 모델이다. 하지만, 이 모델은 attention 연산을 반복하여 수행하기 때문에 계산 복잡도가 높고, 따라서 자원이 한정되어 있는 연합학습 환경에서의 적용이 어렵다는 한계를 가진다. 또한, Perceiver IO라는 모델이 기존 중앙 학습 환경에서의 적용을 염두에 두고 만들어진 모델이기 때문에, 이 모델 자체를 연합 학습 환경에서 사용하기 위해서는 모델 구조의 수정이 필요하다. 이 문제를 해결하기 위해, 본 연구는 Perceiver IO의 attention 연산을 경량화하였고, 연합 학습 환경에 맞추어 구조를 수정하였다. 마지막으로, attention 연산 경량화에 있어 데이터를 압축하는 파라미터를 동적으로 선택하도록 하여, 최적화가 더욱 효율적으로 수행될 수 있도록 하였다. |
| (4) 기대효과 및 의의 | 1. **다양한 모달리티 조합을 수용하는 범용 연합학습 프레임워크 실현** <br> 본 연구는 Perceiver IO의 다양한 모달리티를 통합할 수 있는 능력을 활용해, 다양한 조합의 모달리티를 받아들일 수 있는 연합학습 환경을 제안한다. 이는 기존의 제한된 모달리티 조합만을 처리할 수 있는 연합학습 연구들과 차별화되며, 현실적인 데이터 다양성을 반영한 시스템 설계라는 점에서 높은 의의가 있다. <br><br> 2. **연합학습 환경에 적합한 고성능 멀티모달 모델의 경량화**  <br> 계산량이 많고 메모리 사용이 큰 Perceiver IO 모델을 경량화하고 구조를 수정함으로써, 자원이 제한된 디바이스(예: 모바일, 센서 장치)에서도 학습 참여가 가능하도록 하였다. 이는 연합학습의 실제 적용 가능성을 크게 높이며, 다양한 실세계 응용(의료, 스마트홈, 사용자 행동 분석 등)에 바로 활용될 수 있다. <br><br> 3. **학술적 기여와 후속 연구 기반 마련** <br> 본 프로젝트는 Perceiver IO 기반의 경량화 및 구조 수정이라는 새로운 시도를 통해, 범용 멀티모달 모델의 연합학습 적용 가능성을 실험하였다. 이는 이와 같은 범용 멀티모달 모델의 최적화와 분산 학습 환경에서의 적용과 관련된 연구에 있어 기초적인 참고 사례로 사용될 수 있는 의의를 가진다. |
| (5) 주요 기능 리스트 | 1. **Linformer를 통한 Perceiver IO 경량화** <br> Perceiver IO는 반복적인 attention 연산을 수행해 연합학습 환경에서의 적용은 어려운 계산 복잡도가 큰 무거운 모델이라는 한계점을 가진다. 이 점을 해결하기 위해 Transformer의 attention 연산을 선형 시간에 수행할 수 있도록 경량화한 모델인 Linformer를 사용하였고, 이를 적용한 Perceiver IO를 Linformer IO로 명명했다. 이를 통해 계산 복잡도를 O(N^2)에서 O(kN)으로 줄이면서, 모델의 크기와 추론 시간을 모두 감소시킬 수 있게 된다. <br><br> 2. **연합학습을 위한 Perceiver IO 구조 설계** <br> Perceiver IO라는 모델이 중앙 학습을 위한 모델이고, 기존의 다른 모델들과는 다르게 weight를 합산하여 나누고 다시 분배할 수 있는 구조를 가진 모델이 아니기 때문에, 이를 연합학습 환경에 통합하기 위한 독자적인 구조를 설계하는 것이 필요했다. 이를 위해 본 연구에서는 Perceiver IO를 크게 Shared Latent Perceiver와 Perceiver Head로 나누어 Perceiver IO 모델로도 연합 학습이 가능하도록 하였다. <br><br> 3. **동적으로 데이터 압축 정도 선택 구현** <br> Linformer에서의 근사에서는 projection 차원 k가 큰 영향을 미친다. 이 축소 과정을 본 연구에서는 특정 값으로 설정하는 것이 아니라, 데이터에 따라 변동 가능하도록 하여 데이터 압축과 효율성 사이의 적절한 사이를 찾아 효과적으로 모델의 경량화가 가능하도록 하였다.|

<br>
 

# Project-Design & Implementation

| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 |   <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/2%EC%B0%A8%EB%B3%B4%EA%B3%A0%EC%84%9C-%EA%B7%B8%EB%A6%BC1.jpg?raw=true" alt="2차보고서-그림1" width= 900/> <br><br>**1. 경량화** <br> - Linceiver IO는 Perceiver IO에 비해 빠른 학습 속도를 보이고, 더 적은 용량의 모델 크기를 갖춰야 한다. <br> - Attention 연산의 복잡도를 기존 $O(N^2)$에서 $O(kN)$으로 줄이기 위한 Low-Rank Projection 기반의 구조(Linformer 방식)를 적용해야 한다. <br> - 모델 파라미터 수는 가능한 한 최소화하여 연합학습 클라이언트에서 동작할 수 있도록 경량화를 달성해야 한다. <br><br> **2. 범용성** <br> - Linceiver IO는 다양한 크기의 데이터, 더 나아가 다양한 모달리티 데이터에서 안정적인 학습 효과를 보여야 한다. <br> - Linceiver IO의 projection 차원 k는 학습 과정에서 동적으로 변경 가능하며, 정확도와 학습 속도 및 용량에서 최적의 Trade-off를 만족하는 수치로 설정되어야 한다. <br><br> **3. 연합학습 적용성** <br> - 기존 Perceiver IO가 연합학습에 적용된 사례가 없는 만큼, 본 프로젝트는 Linceiver IO의 구조를 연합학습 시스템에 최적화하여 새롭게 설계해야 한다. <br> - 연합학습 환경에서 Shared Latent Perceiver와 개별 클라이언트의 Perceiver Head로 구성된 하이브리드 구조를 적용해야 한다. <br> - 클라이언트 단은 독립적인 데이터셋을 기반으로 로컬 학습을 수행하며, 중앙 서버는 각 클라이언트로부터 데이터를 수합하지 않고, Shared Latent Perceiver의 가중치를 받아 평균화하는 방식으로 학습을 통합해야 한다. <br> - 학습된 모델은 중앙집중형 학습 모델 대비 유사하거나 더 나은 성능을 달성해야 한다. |
| (2) 전체 시스템 구성 | *실험 환경 구성은 아래 다이어그램과 같다.* <br><br> <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/%EC%8B%9C%EC%8A%A4%ED%85%9C%EA%B5%AC%EC%A1%B0.jpg?raw=true" alt="시스템 구성도" width="900"/> <br><br> **1. User (연구팀원)** <br> - 개인 PC 또는 노트북에서 VS Code를 실행하고 원격 서버에 접속함 <br> - 서버 내부의 코드 작성, 실행, 디버깅을 수행함 <br><br> **2. VS Code Remote - SSH** <br> - 사용자의 로컬 VS Code에서 서버에 안전하게 접속하게 해주는 도구 <br> - 코드 수정, 실험 실행 등을 로컬에서 바로 하듯이 원격으로 수행 가능 <br><br> **3. ML/DL 개발환경** <br> - Python과 PyTorch 기반의 소프트웨어 환경이 구성되어 있음 <br> - 아나콘다 가상환경으로 통일된 패키지 및 라이브러리 버전 유지 <br><br> **4. GPU 서버 환경** <br> - 실제 연산이 수행되는 장소로, 고성능 GPU가 장착된 서버임 <br> - Ubuntu 리눅스 OS를 기반으로 실행되며, PyTorch에서 GPU를 활용해 모델 학습과 추론을 처리함 <br><br> 추가로, 요구사항 만족을 위해 아래와 같은 세 가지 실험를 설계하였다. <br><br>  <img src= "https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/2%EC%B0%A8%EB%B3%B4%EA%B3%A0%EC%84%9C-%EA%B7%B8%EB%A6%BC2.jpg?raw=true" alt="2차보고서-그림2" width= 900/> <br> *각 실험의 진행 방법을 나타내는 구조도 및 실험 목적은 아래와 같다.* <br><br> **1. 실험 1: Linceiver IO의 경량화 효과 검증** <br> <img src= "https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/2%EC%B0%A8%EB%B3%B4%EA%B3%A0%EC%84%9C-%EC%8B%A4%ED%97%981%EA%B5%AC%EC%A1%B0%EB%8F%84.jpg?raw=true" alt="2차보고서-실험1구조도" width= 900/> <br> 실험 1에서는 Linceiver IO의 경량화 효과를 검증하기 위해 압축 차원인 k에 따른 학습 경향을분석했다.  k값으로는 (32, 64, 128, 256, 512, 784)를 사용했고, k=784의 경우 원본 이미지 사이즈인 28*28 이므로 압축을 전혀 하지 않았을 경우를 의미한다. 검증을 위해서 Fashion-MNIST 데이터셋 분류 실험을 수행했다. 각 k에 대해 30 epoch 학습 루프를 10회의 반복 실험하였으며, 평균 학습 경향을 계산했다. 평가 메트릭으로는 정확도, 모델 사이즈, 30 epoch에 소요되는 학습 시간을 설정했다.  <br><br> **2. 실험 2: Adaptive K 검증** <br> <img src ="https://github.com/kyungh2e2e/CapstoneDesignProject/blob/74ccc4c6d7e777a54a1a9921480968a86fb7e2ea/%EA%B5%AC%EC%A1%B0%EB%8F%84.png?raw=true" width= 900/><br>실험 2에서는 Perceiver IO에 Linformer 기반 Adaptive Low-Rank Attention을 통합한 Linceiver IO 모델이 입력 복잡도에 따라 압축 차원 k를 동적으로 최적화할 수 있는지를 확인하고자 하였다. 이를 위해 단순한 입력을 가지는 MNIST와 복잡한 입력을 가지는 CIFAR-10 데이터셋에 동일한 Linceiver IO 구조를 적용하고, 학습 도중 변화하는 effective k의 양상과 성능 지표를 비교하였다. 결과적으로, 이 실험을 통해 Linceiver IO가 입력의 복잡도에 따라 k값을 자동으로 조절하는 메커니즘이 실제로 작동함을 보이고, 다양한 데이터 환경에서도 범용적이고 효율적인 저차원 Attention 구조로 기능할 수 있음을 실험적으로 입증하고자 하였다.<br><br> **3. 실험 3: 연합학습 효과 검증** <br> <img src= "https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/2%EC%B0%A8%EB%B3%B4%EA%B3%A0%EC%84%9C-%EC%8B%A4%ED%97%983%EA%B5%AC%EC%A1%B0%EB%8F%84.jpg?raw=true" alt="2차보고서-실험3구조도" width= 900/> <br> *실험 1에서는 Linceiver IO의 경량화 효과를 검증하기 위해 압축 차원 k를 달리 하는 Stand-Alone 모델을 사용했다. 실험 3의 목적은 Linceiver IO를 연합학습 클라이언트 모델로 사용할 경우, Stand-Alone 모델에 비해 학습 성능과 학습 시간 면에서 더 효율적인 학습을 할 수 있음을 보이기 위함이다. 또한, 각 연합학습 실험에 사용되는 Linceiver IO의 압축차원 k를 {32, 64, 128, 256, 512, 784}로 달리하여 압축차원 k의 변화가 전체 연합학습 성능 및 시간에 어떠한 영향을 미치는 지 평가하고자 하였다. 결과적으로, 이 실험을 통해 제한한 Linceiver IO 모델의 연합학습 적용 가능성과 효율성을 실험적으로 입증하고자 하였다.* |
| (3) 주요엔진 및 기능 설계 | *첫 번째로 실험 환경에 대한 설계는 아래와 같다.* <br><br> **1. VS Code Remote SSH** <br> - 팀원과 서버 간의 연결을 중계하는 원격 개발 도구로, 로컬에서 VS Code를 실행하고 Remote SSH 확장을 통해 서버에 접속함 <br> - 서버 내부 파일을 직접 수정하거나 실행 가능하며, Microsoft에서 개발한 오픈소스 확장 기능임 <br><br> **2. Python 3.8.20** <br> - 프로젝트의 주 개발 언어로, 다양한 머신러닝 라이브러리와의 높은 호환성으로 채택됨 <br><br> **3. PyTorch 1.10.2** <br> - Perceiver IO 및 Linceiver IO 모델 구현, 학습 및 추론에 사용되는 Python 기반 딥러닝 프레임워크 <br><br> **4. Ubuntu 20.04.6** <br> - 서버 운영체제로 사용되는 오픈소스 기반 리눅스 배포판 <br><br> **5. NVIDIA GeForce RTX 3070** <br> - CUDA 기반 GPU 연산 가속이 가능한 고성능 그래픽카드로, PyTorch와 호환되어 빠른 연산을 지원함 <br><br> **6. Anaconda 가상환경** <br> - 패키지 의존성 충돌 방지를 위해 모든 개발자가 동일한 환경을 사용함 <br> - 환경 복제를 통해 실험의 재현성 확보 가능 <br><br> *세 가지 실험에 대한 실험 방법은 아래와 같다. (각자 맡은 실험에 대하여 실험 방법 서술하기)* <br><br> ***1. 실험 1: Linceiver IO의 경량화 효과 검증** (실험방법서술) <br><br> **2. 실험 2: Adaptive K 검증**<br> **Step 1)** 동일한 구조의 Linceiver IO 모델을 정의한다. 모델은 Cross-Attention과 Self-Attention에 모두 Adaptive Linformer Attention 모듈을 사용하며, `latent_dim=64`, `num_latents=64`, `depth=2`, `k_max=128`로 고정한다. CIFAR-10 모델에는 Learnable Positional Encoding과 Sinusoidal PE를 함께 적용한다. <br>**Step 2)** 입력 데이터셋으로 MNIST와 CIFAR-10을 사용한다. MNIST는 28×28 흑백 이미지를 784개의 시퀀스로 flatten하여 1차원으로 임베딩하고, CIFAR-10은 32×32×3 이미지를 (1024, 3) 시퀀스로 reshape한 후 3차원 RGB 벡터를 임베딩한다. <br>**Step 3)** 학습 파라미터를 설정한다. MNIST는 `Adam (lr=5e-4)`을 사용하고, CIFAR-10은 `AdamW (lr=2e-4, weight_decay=1e-2)`와 `CosineAnnealingLR` 스케줄러를 함께 사용한다. 두 실험 모두 학습 epoch는 `50`으로 설정한다. <br>**Step 4)** 학습을 수행하면서 각 epoch마다 `train loss`, `test loss`, `test accuracy`를 기록하고, Adaptive `effective k` 값을 계산한다. `effective k`는 `sigmoid(gate_k) * alpha_k`의 평균값으로 정의된다. <br>**Step 5)** 실험 종료 후 기록된 `k` 변화 그래프 및 정확도 그래프를 비교 분석한다. 입력 복잡도에 따른 `effective k`의 조절 양상을 통해 Linceiver IO의 동적 적응 능력을 평가하고, 모델의 범용성과 효율성을 확인한다. <br><br> **3. 실험 3: 연합학습 효과 검증** <br> **Step 1)** 10개의 클라이언트 모델을 생성한다. 이때, 각 클라이언트 모델은 (Shared Latent Perceiver, Perceiver Head) 쌍으로 분리한 Linceiver IO로 구성된다. Linceiver IO의 압축차원 k는 `--k` 매개변수를 통해 설정 가능하며, k = {32, 64, 128, 256, 512, 784}에 대해 아래의 과정을 반복한다. <br>**Step 2)** Fashion-MNIST 데이터셋을 10개의 클라이언트에 분할하여 분배한다. `--iid` 옵션에 따라 IID 혹은 non-IID 방식으로의 데이터 분할이 가능한데, 이 실험에서는 IID 방식으로 분할했다. <br> **Step 3)** 학습에 필요한 기타 파라미터를 설정한다. 매 글로벌 라운드 별 클라이언트 참여 비율인 `--frac`는 `1.0`으로 설정하여 전체 클라이언트가 매 글로벌 라운드에 참여하도록 했다. `--local_ep`는 `5`로 설정하여 다섯 번의 로컬 학습마다 한 번의 Global round가 수행되도록 설정했다. <br> **Step 4)** 연합학습을 시작한다. 매 글로벌 라운드마다 각 클라이언트의 loss, accuracy 를 txt파일로 저장하고, 학습 파이프라인이 끝날 때 총 학습 시간을 기록하도록 구현했다. <br> **Step 5)** Step 4에서 생성된 결과 txt 파일을 분석한다. 각 클라이언트이 최종 accuracy를 표로 기록하고, 정확도의 평균과 중간값을 계산한다. 계산한 결과를 토대로 Stand-Alone 모델과의 차이를 분석한다.* |
| (4) 주요 기능의 구현 | **1. Perceiver IO의 Attention 연산을 경량화** <br> 본 논문에서는 범용성이 뛰어난 Perceiver IO 모델을 컴퓨팅 자원이 부족한 연합학습 클라이언트에 적용하기 위한 경량화 모델인 Linceiver IO를 제안한다. Linceiver IO의 경우 Perceiver IO의 attention 연산에 low-rank projection을 활용하는 Linformer 구조를 적용하여 계산 복잡도를 $O(N^2)$에서 $O(kN)$로 줄일 수 있다. 설계한 Linceiver IO의 구조는 아래와 같다. <br><br> <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/linceiver%20io%20%EA%B5%AC%EC%A1%B0.jpg?raw=true" alt="Linceiver IO 구조도" width="900"/> <br><br> **2. 다양한 사이즈 및 모달리티 데이터에 범용적으로 사용 가능한 모델 설계** <br> Low-Rank Projection에서 사용하는 k값은 학습가능한 파라미터를 추가하여 학습과정에서 다른 파라미터들과 같이 업데이트 된다. 입력 데이터에 따라 각 Low-rank Projection 차원의 상대적 중요도를 동적으로 결정하여, 필요한 정보만 효과적으로 선택하고, 불필요한 차원의 정보를 억제함으로써 효율적인 학습을 수행할 수 있다. <br><br> **3. 설계한 모델에 맞는 새로운 연합학습 구조 제안** <br> Perceiver IO 구조를 연합학습에 적용한 사례가 없기 때문에, 설계한 모델이 연합학습 환경에서 잘 동작할 수 있게끔 연합학습 구조와 시스템, 정책 등을 독자적으로 설계하였다. 본 연구에서는 Linceiver IO를 Shared Latent Perceiver, Perceiver Head로 분리하여 연합학습 시스템을 설계했다. Shared Latent Perceiver는 연합학습 환경에서 모든 클라이언트가 공유하는 백본 네트워크로 동작하며, 클라이언트들이 학습한 가중치를 수집하고 평균화하여 지속적으로 업데이트하도록 했다. 한편, 클라이언트는 자체적인 Embedding Layer, Perceiver Head와 함께 학습 가능한 Query Vector를 보유하고 있으며, 독립적인 로컬 데이터셋을 활용하여  학습한다. 전체 연합학습 시스템의 구조도는 아래와 같다. <br><br> <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/%EC%97%B0%ED%95%A9%ED%95%99%EC%8A%B5%EA%B5%AC%EC%A1%B0.jpg?raw=true" alt="연합학습 구조도" width="900"/> 클라이언트는 자체적인 Embedding Layer, Perceiver Head와 함께 학습 가능한 Query Vector를 보유하고 있으며, 독립적인 로컬 데이터셋을 활용하여 학습, 데이터 프라이버시를 달성한다. 클라이언트별 학습이 완료되면, 각 클라이언트는 공유 백본의 가중치를 서버로 전송하고, 서버는 이를 평균화하여 백본을 동기화한다. $W_k$는 $i$번째 연합학습 라운드에서 클라이언트 k가 학습한 백본 가중치를 의미하며, 모든 k에 대한 평균이 $i+1$번째 라운드에서 사용될 새로운 글로벌 백본 가중치가 된다. 한편, 수식에서 N은 연합학습 클라이언트의 수이다.|
| (5) 기타 (실험 결과) | 세 가지 실험에 대한 실험 결과 및 결론은 아래와 같다. **1. 실험 1: Linceiver IO의 경량화 효과 검증** (실험결과 추가) <br><br> **2. 실험 2: Adaptive K 검증** <br><img src="https://github.com/kyungh2e2e/CapstoneDesignProject/blob/8572fb0b73a1b595cf0d7aa9d2afaeac4e713d51/k%EB%B3%80%ED%99%94.png?raw=true" width="900"/> <br> 첫 번째 그래프는 MNIST와 CIFAR-10 각각에 대해 Adaptive k의 평균값이 epoch에 따라 어떻게 변화하는지를 나타낸다.<br>MNIST에서는 학습 초기 약 60 수준에서 시작된 k가 매우 빠르게 감소하며, 10 epoch 이후에는 20 이하로 낮아지고, 최종적으로는 5 이하로 수렴하였다. 이는 정보량이 적은 단순한 흑백 이미지에 대해 모델이 불필요한 차원을 빠르게 제거하고, 최소한의 표현만으로 학습을 효율화하고자 하는 동작을 보여준다. CIFAR-10에서는 k가 초기 약 78에서 점진적으로 감소하여 epoch 25 부근에서 최소 66 수준까지 도달한 뒤, 이후 다시 서서히 증가하는 U자 형태를 나타냈다. 이는 복잡한 컬러 이미지로 인해 초기에는 보수적으로 차원을 유지하다가, 점차 입력 구조를 파악하면서 차원을 축소하되, 과도한 정보 손실을 방지하기 위해 일부 차원을 다시 활성화시키는 adaptive behavior로 해석할 수 있다.<br>결과적으로 두 그래프는 Linceiver IO가 입력의 복잡도에 따라 압축 차원을 자동으로 조절하고 있으며, 정보 손실을 최소화하면서도 연산 효율을 극대화하는 자기 조정형 Attention 구조의 가능성을 실험적으로 입증하는 근거가 된다. <br> <img src="https://github.com/kyungh2e2e/CapstoneDesignProject/blob/8572fb0b73a1b595cf0d7aa9d2afaeac4e713d51/acc%EB%B3%80%ED%99%94.png?raw=true" width=900/> <br> 두 번째 그래프는 각 데이터셋에 대해 epoch별 Test Accuracy를 나타낸 것이다.<br>MNIST 실험에서는 초기 epoch부터 빠르게 높은 정확도(최대 98.5%)에 도달했으며, 모델이 압축된 attention에서도 정보를 손실 없이 효과적으로 처리했음을 보여준다. CIFAR-10 실험에서는 더 많은 epoch이 필요했으며, 학습이 진행됨에 따라 점진적으로 정확도가 향상되었고, effective k 감소와 함께 정합적으로 test accuracy도 함께 상승하는 추세를 나타냈다.<br>이는 Adaptive k가 단순히 연산량을 줄이기 위한 장치가 아니라, 실제로 입력 정보의 유의미한 압축 수준을 학습하고 있음을 시사한다. 즉, 학습 성능에 부정적 영향을 주지 않으면서도 압축을 수행할 수 있는 최적 수준의 k값을 찾아가는 구조로 작동함을 확인할 수 있다.<br><br>따라서, 실험 2를 통해 Linceiver IO는 데이터의 복잡도에 따라 압축 차원 k를 스스로 조절하며, 효율적으로 학습을 수행할 수 있는 구조임을 입증하였다. 입력 정보량이 적은 경우에는 k를 빠르게 줄여 연산 자원을 절약하고, 복잡한 입력에 대해서는 필요한 수준의 표현력을 확보하기 위해 k를 유지하거나 서서히 감소시키는 양상을 보였다. 이러한 결과는 Linceiver IO가 다양한 입력 환경에서도 안정적이고 유연하게 작동할 수 있는 Self-Adaptive Attention 기반 압축 구조로서의 가능성을 실험적으로 뒷받침해준다. <br><br> **3. 실험 3: 연합학습 효과 검증** <br> <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/2%EC%B0%A8%EB%B3%B4%EA%B3%A0%EC%84%9C-%ED%91%9C1.jpg?raw=true" alt="연합학습결과표1" width="900"/>  첫 번째 표는 압축차원 k에 따라 연합학습 실험을 수행, 10회의 Global round 이후 각 클라이언트의 정확도를 정리한 것이다. 각 압축 차원에서 가장 높은 정확도를 보인 클라이언트는 굵은 글씨로 표시하였으며, 모든 클라이언트의 최종 정확도에 대한 평균값과 중간값을 계산하였다. 더 높은 압축차원을 가질수록 연합학습 성능이 높아짐을 알 수 있다.<br> <br><br> <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/2%EC%B0%A8%EB%B3%B4%EA%B3%A0%EC%84%9C-%ED%91%9C2.jpg?raw=true" alt="연합학습결과표2" width="900"/> 두 번째 표는 Linceiver IO를 Stand-Alone으로 사용했을 때와, 연합학습에 사용했을 때의 정확도를 비교한 표이다. 연합학습을 사용할 경우 모든 k에서 Stand-Alone보다 정확도 평균 및 중간값이 높았으며, 최대 16.8%의 정확도 향상을 보였다. 한편, Stand-Alone 모델의 정확도는 30 epoch의 학습 루프 수행 결과로 정의하였다. <br><br> <img src="https://github.com/yeongeunshim/CapstoneDesignProject/blob/main/2%EC%B0%A8%EB%B3%B4%EA%B3%A0%EC%84%9C-%EA%B7%B8%EB%9E%98%ED%94%84%EC%97%B0%ED%95%A9%ED%95%99%EC%8A%B5%EC%8B%9C%EA%B0%84.png?raw=true" alt="연합학습결과표2" width="900"/> 위 그래프는 Stand-Alone 모델과 연합학습의 학습 시간을 비교한 그래프이다. Stand-Alone 모델의 경우 하나의 모델의 30 epoch 학습에 걸린 시간이며, 연합학습은 5 local epoch * 10 global round, 총 50 epoch에 해당하는 학습에서의 전체 소요 시간이다. 절대적인 비교보다는 상대적 추세와 자원 효율 관점에서 참고할 수 있다. 그래프에서 확인할 수 있듯이 Linceiver IO를 연합학습에 활용하면 k가 커짐에도 학습 시간의 증가 폭은 Stand-Alone 학습에 비해 적다는 장점이 있다. 연합학습에서는 클라이언트별 로컬 학습이 병렬적으로 수행되므로, 전체 학습 시간은 Stand-Alone 학습에 비해 압축 차원 의 증가에 따른 영향이 제한적이다. 반면, Stand-Alone 학습은 모델 전체가 순차적으로 학습되기 때문에  증가 시 연산 복잡도가 직접적으로 학습 시간 증가로 이어진다. 이로 인해 연합학습은 상대적으로 높은  설정에서도 안정적인 학습 시간 특성을 유지할 수 있다.  |

<br>
